{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f7c105",
   "metadata": {},
   "source": [
    "# +AUC +sen +spe 转test3计算均值\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "from pylab import rcParams\n",
    "import matplotlib.cm as cm\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder  # 编码转换\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier  # 随机森林\n",
    "from sklearn.svm import SVC, LinearSVC  # 支持向量机\n",
    "from sklearn.linear_model import LogisticRegression  # 逻辑回归\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN算法\n",
    "from sklearn.naive_bayes import GaussianNB  # 朴素贝叶斯\n",
    "from sklearn.tree import DecisionTreeClassifier  # 决策树分类器\n",
    "# from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score,accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import sys \n",
    "#print(sys.path)\n",
    "#print(\"当前路径 -> %s\" %os.getcwd())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Nstr:\n",
    "    def __init__(self,arg):\n",
    "        self.x=arg\n",
    "    def __sub__(self,other):\n",
    "        c=self.x.replace(other.x,\"\")\n",
    "        return c\n",
    "\n",
    "\n",
    "\n",
    "filename= os.listdir(r'C:\\\\Users\\Xia HAN\\\\Downloads\\\\jupyter_code_data_WEI_kunni\\\\code_20221124\\\\color4')##\n",
    "                           \n",
    "#print(filename) ## filename为该表格的所有sheet，如'sheet1','sheet2','sheet3'\n",
    "\n",
    "for i in range(len(filename)):\n",
    "    print(\"正在处理第\"+str(i)+\"文件，\")\n",
    "#for i in range(0,1):    #########此行为测试时用\n",
    "    totaldata = pd.read_excel(filename[i], sheet_name=4)\n",
    "    totaldata.dropna(inplace=True)\n",
    "    for j in range(3,12):###控制特征向量的长度\n",
    "    #for j in range(3,4):  #########此行为测试时用\n",
    "        #print(filename[i])##########此行为测试用\n",
    "        print(\"此时特征向量长度为\"+str(j-2)+\"...\")\n",
    "        brain = totaldata.iloc[:, 2:j]  ##############################################更改特征向量长度,从1-9\n",
    "        #print(brain)\n",
    "        scaler = StandardScaler(copy=False)\n",
    "        scaler.fit_transform(brain)\n",
    "        \n",
    "        brain = scaler.fit_transform(brain)\n",
    "        k= 100                                 ##########################################100  修改计算次数\n",
    "        X=brain\n",
    "        \n",
    "        y=totaldata[\"group\"].values\n",
    "        sum_result = 0\n",
    "        list_result=[]\n",
    "        list_result_time=[]\n",
    "        Classifiers = [\n",
    "            [\"Random Forest\", RandomForestClassifier()],\n",
    "            [\"Support Vector Machine\", SVC()],\n",
    "            [\"LogisticRegression\",LogisticRegression()],\n",
    "            [\"KNN\",KNeighborsClassifier(n_neighbors=5)],    ########### K=5\n",
    "            # [\"Naive Bayes\",GaussianNB()],\n",
    "            [\"Decision Tree\",DecisionTreeClassifier()],\n",
    "            # [\"AdaBoostClassifier\", AdaBoostClassifier()],\n",
    "            # [\"GradientBoostingClassifier\", GradientBoostingClassifier()],\n",
    "            # [\"XGB\", XGBClassifier()],\n",
    "            [\"CatBoost\", CatBoostClassifier(logging_level='Silent')]\n",
    "        ]\n",
    "        sss = StratifiedShuffleSplit(n_splits=k, test_size=0.3, random_state=None)# n_splits：是将训练数据分成train/test对的组数\n",
    "                                                                                   # train：test=7：3\n",
    "        for train_index, test_index in sss.split(X, y):\n",
    "            #print(\"train:\", train_index, \"test:\", test_index)\n",
    "            X_train,X_test=X[train_index], X[test_index]\n",
    "            y_train,y_test=y[train_index], y[test_index]\n",
    "            \n",
    "            Classify_result = []\n",
    "            names = []\n",
    "            prediction = []\n",
    "            times=[]\n",
    "            \n",
    "            for name, classifier in Classifiers:   ##此时分类器类别个数为6\n",
    "                #print(name)\n",
    "                #print()\n",
    "                start = time.time()\n",
    "                classifier = classifier\n",
    "                classifier.fit(X_train, y_train)\n",
    "                y_pred = classifier.predict(X_test)\n",
    "                acc_score = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                class_eva = pd.DataFrame([acc_score])\n",
    "                Classify_result.append(class_eva)\n",
    "                \n",
    "                name = pd.Series(name)\n",
    "                names.append(name)\n",
    "                \n",
    "                end = time.time()\n",
    "                exe_time = str(round((end-start),6))\n",
    "                \n",
    "                exe_time = pd.DataFrame([exe_time])\n",
    "                times.append(exe_time)\n",
    "                \n",
    "                #print(exe_time)\n",
    "                \n",
    "            names = pd.DataFrame(names)  ##这里的names是分类器的名称\n",
    "            ##print(names)\n",
    "            names = names[0].tolist()\n",
    "            ##print(names[0])\n",
    "            result = pd.concat(Classify_result, axis=1)#axis=1为列合并\n",
    "            result_time=pd.concat(times,axis=1)\n",
    "            ##print(result) \n",
    "            result.columns = names\n",
    "            result_time.columns = names\n",
    "            result.index = [\"acc_score\"]\n",
    "            result_time.index = [\"exe_time\"]\n",
    "            list_result.append(result)\n",
    "            list_result_time.append(result_time)\n",
    "\n",
    "            #sum_result += result\n",
    "        avg_result = pd.concat(list_result, axis=0) ##axis=0为基于行合并\n",
    "        #print(avg_result)\n",
    "        avg_result_time = pd.concat(list_result_time, axis=0)\n",
    "        \n",
    "        #print(exe_time)\n",
    "        \n",
    "        fileName_xlsx = Nstr(str(filename[i]))\n",
    "        fileName_suffix = Nstr(\".xlsx\")\n",
    "        new_fileName = fileName_xlsx - fileName_suffix\n",
    "        new_fileName = new_fileName+\"_\"+str(j-2)+\"_\"\n",
    "        avg_result.to_csv((new_fileName+\"vectorLongeur\"+\".csv\"))  ###写文件这里\n",
    "        avg_result_time.to_csv((new_fileName+\"exeTime\"+\".csv\"))\n",
    "        \n",
    "        ##time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515f32a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
